{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This file shows the steps taken when generating the Namarsh dataset\n",
    "\n",
    "The first step was to extract data from .html files\n",
    "The data is: the name of the sections from the website and texts from the articles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The library to extract data from HTML\n",
    "from bs4 import BeautifulSoup\n",
    "# The library used for data manipulation: https://pandas.pydata.org\n",
    "import pandas as pd\n",
    "# The libraries to access local files and folders which will be used to iterate over thousands of .html files in the namarsh folder\n",
    "import os\n",
    "import glob"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Further, the folder that contains Namarsh HTML files in defined.\n",
    "full = [] creates a new array where processed data will then be stored during the next step."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "files = glob.glob('materials/*.html')\n",
    "full = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next step is to iterate over the HTML files in the folder and pull the website articles.\n",
    "The records are then further stored in the dataframe.\n",
    "The subsections are found by <p></p> HTML tag which contains the articles.\n",
    "The search is done using the BeautifulSoup library.\n",
    "All the data is then converted to a data frame for further manipulation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for file in files:\n",
    "\n",
    "    extractor = open(file, 'rb')\n",
    "    soup = BeautifulSoup(extractor, features=\"html.parser\")\n",
    "\n",
    "    text = soup.find_all(\"div\", class_= \"content-container\")\n",
    "    p_text = [p.get_text() for p in text]\n",
    "\n",
    "    full.append([p_text, os.path.basename(file)])\n",
    "\n",
    "df_full = pd.DataFrame(full)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we are creating a function that will run over the dataframe columns and find News of Protest subsection.\n",
    "The first column of df_full is being renamed into ['Name']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def match_cat(column):\n",
    "    if \"Новости протеста\" in column['0']: return column[0]\n",
    "\n",
    "df_full['0'] = df_full.apply(match_cat, axis=1)\n",
    "df_full['Name'] = df_full['0']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a new dataset that will store cleaner data for the dataset for convenience\n",
    "Then the function is applied and null values are removed using dropna() pandas function that does this\n",
    "The output of the function is then stored in the clean dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame()\n",
    "clean_df['Name'] = df_full['Name'].dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since data in the <p></p> still included more markup, the next steps are to get rid of it and split the data into dataset columns.\n",
    "The columns are: title of the event, description, short description (which will be used as the event identifier or title when merged with the Forthcoming Events subsection).\n",
    "The data is stripped in the order it is presented in the articles (title short description in the first paragraph followed by the main description in the second and on).\n",
    "The split is done using the \\t and \\n symbols which were pulled during the <p></p> step together with the data.\n",
    "The \\n symbols are \"new line\", and new lines are used to begin new sections.\n",
    "The 'output_df' will store the final version of the News of Protest subsection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#The date column because <p></p> started with the date\n",
    "output_df = clean_df['Name'].str.split(\"t\", n=1, expand=True)\n",
    "output_df = output_df.drop([0], axis=1)\n",
    "output_df = output_df[1].str.split(\" \", n=1, expand=True)\n",
    "\n",
    "#The title and description columns. The latter contains both the introduction paragraph and main description\n",
    "output_df[['title', 'description']] = output_df[1].str.split(\"n\", n=1, expand=True)\n",
    "output_df['title'] = output_df['title'].str.strip(\"\\\\\")\n",
    "output_df['description'] = output_df['description'].str.strip(r\"\\n\")\n",
    "output_df = output_df.drop([1], axis=1)\n",
    "\n",
    "#Split description in \"short description\" and \"details\"\n",
    "output_df[['short_description', 'details']] = output_df['description'].str.split(\"n\", n=1, expand=True)\n",
    "output_df['short_description'] = output_df.short_description.str.strip(\"\\\\\")\n",
    "output_df['details'] = output_df.details.str.strip(r\"\\n\")\n",
    "\n",
    "# Get rid of the original column since it has been split\n",
    "output_df = output_df.drop(['description'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that the data is split into columns, the next step is to remove unnecessary symbols that contaminate the dataset.\n",
    "For this, the cleaner() function is introduced which replaces the symbols with \" \""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cleaner(data):\n",
    "    lister = {r'\\r', r'\\n', r'\\xa0'}\n",
    "    for i in lister:\n",
    "        data = data.replace(i, \" \")\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function is then applied to relevant columns with extra symbols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_df['short_description'] = output_df['short_description'].apply(str).apply(lambda x: cleaner(x))\n",
    "output_df['details'] = output_df['details'].apply(str).apply(lambda x: cleaner(x))\n",
    "\n",
    "# Additional cleaning\n",
    "output_df['short_description'] = output_df['short_description'].str.replace(r'\\s+', ' ', regex=True)\n",
    "output_df['details'] = output_df['details'].str.replace(r'\\s+', ' ', regex=True)\n",
    "output_df['details'] = output_df['details'].str.strip(r'\\']')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To extract locations out of the data, string matching needs to be done.\n",
    "For that, a list of Russian cities is exported and iterated one by one.\n",
    "To find out if the description contains any of the cities from the list, it needs to be iterated over.\n",
    "The matching lines are then stored in an array.\n",
    "The array is then connected to the dataframe.\n",
    "This is done using the city_extractor() function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The list of cities is imported\n",
    "cities_list = pd.read_csv('towns.csv')\n",
    "\n",
    "def city_extractor(row):\n",
    "    for cities in cities_list['city']:\n",
    "        if cities in row.short_description: return cities\n",
    "        if row.cities == 'None' and cities in row.details: return cities\n",
    "    return 'None'\n",
    "\n",
    "#This line is specific to the Russian language because it has the declension system which changes the ending of words\n",
    "#The purpose is to remove the vowels from the ending to keep the root of the word and use this root to find matches\n",
    "cities_list['city'] = cities_list['city'].apply(lambda x: x[:-1] if x[-1] in set('аея') else x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function is then applied\n",
    "The words with missing ending vowels are returned"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_df['cities'] = output_df.apply(city_extractor, axis=1)\n",
    "\n",
    "replacements = {\n",
    "    'cities': {\n",
    "        \"Москв\" : \"Москва\", \"Калуг\" : \"Калуга\", \"Тул\" : \"Тула\", \"Самар\" : \"Самара\", \"Раменск\" : \"Раменское\",\n",
    "        \"Балаших\" : \"Балашиха\", \"Костром\" : \"Кострома\", \"Вологд\" : \"Вологда\", \"Кашир\" : \"Кашира\", \"Донецк\" : \"None\",\n",
    "        \"Козловк\" : \"Козловка\", \"Махачкал\" : \"Махачкала\", \"Туапс\" : \"Туапсе\",\n",
    "        \"Чит\" : \"Чита\", \"Пенз\" : \"Пенза\", \"Каменк\" : \"Каменка\", \"Кушв\" : \"Кушва\", \"Тарус\" : \"Таруса\",\n",
    "        \"Ухт\" : \"Ухта\", \"Уф\" : \"Уфа\", \"Находк\" : \"Находка\", \"Балахн\" : \"Балахна\", \"Юрг\" : \"Юрга\", \"Раменско\" : \"Раменское\",\n",
    "        \"Лобн\" : \"Лобна\"}\n",
    "    }\n",
    "\n",
    "output_df.replace(replacements, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The last step is to save the output to CSV file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "newer.to_csv(\"test.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}